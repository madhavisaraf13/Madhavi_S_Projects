{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course : Natural Language Processing (CS6120)\n",
    "### Assignment 0 Solution\n",
    "#### Author : Team G\n",
    "#### Team members : Madhavi Arvind Saraf, Rahil Jhaveri, Chenxi Qu\n",
    "\n",
    "#### Part A Solution\n",
    "##### Assumption : We have assumed that Columns such as State, City and County are based in USA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone_1</th>\n",
       "      <th>Phone_2</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Company name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>Butt</td>\n",
       "      <td>6649 N Blue Gum St</td>\n",
       "      <td>jbutt@gmail.com</td>\n",
       "      <td>504-621-8927</td>\n",
       "      <td>504-845-1427</td>\n",
       "      <td>Benton</td>\n",
       "      <td>Orleans</td>\n",
       "      <td>LA-Louisiana</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josephine</td>\n",
       "      <td>Darakjy</td>\n",
       "      <td>4 B Blue Ridge Blvd</td>\n",
       "      <td>josephine_darakjy@darakjy.org</td>\n",
       "      <td>810-292-9388</td>\n",
       "      <td>810-374-9840</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>Livingston</td>\n",
       "      <td>MI-Michigan</td>\n",
       "      <td>Chanay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Art</td>\n",
       "      <td>Venere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>856-636-8749</td>\n",
       "      <td>856-264-4130</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>Gloucester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chemel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenna</td>\n",
       "      <td>Paprocki</td>\n",
       "      <td>639 Main St</td>\n",
       "      <td>lpaprocki@hotmail.com</td>\n",
       "      <td>907-385-4412</td>\n",
       "      <td>907-921-2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AK-Alaska</td>\n",
       "      <td>Feltz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donette</td>\n",
       "      <td>Foller</td>\n",
       "      <td>34 Center St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Printing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First_Name Last_Name              Address                          Email       Phone_1       Phone_2        City      County         State Company name\n",
       "0      James      Butt   6649 N Blue Gum St                jbutt@gmail.com  504-621-8927  504-845-1427      Benton     Orleans  LA-Louisiana          NaN\n",
       "1  Josephine   Darakjy  4 B Blue Ridge Blvd  josephine_darakjy@darakjy.org  810-292-9388  810-374-9840    Brighton  Livingston   MI-Michigan       Chanay\n",
       "2        Art    Venere                  NaN                            NaN  856-636-8749  856-264-4130  Bridgeport  Gloucester           NaN       Chemel\n",
       "3      Lenna  Paprocki          639 Main St          lpaprocki@hotmail.com  907-385-4412  907-921-2010         NaN         NaN     AK-Alaska        Feltz\n",
       "4    Donette    Foller         34 Center St                            NaN           NaN           NaN    Hamilton         NaN           NaN     Printing"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Please refer the method documentation for detailed working\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "\n",
    "# list of all the US city names\n",
    "US_city_names = [\"Aberdeen\", \"Abilene\", \"Akron\", \"Albany\", \"Albuquerque\", \"Alexandria\", \"Allentown\", \"Amarillo\", \"Anaheim\", \"Anchorage\", \"Ann Arbor\", \"Antioch\", \"Apple Valley\", \"Appleton\", \"Arlington\", \"Arvada\", \"Asheville\", \"Athens\", \"Atlanta\", \"Atlantic City\", \"Augusta\", \"Aurora\", \"Austin\", \"Bakersfield\", \"Baltimore\", \"Barnstable\", \"Baton Rouge\", \"Beaumont\", \"Bel Air\", \"Benton\", \"Bellevue\", \"Berkeley\", \"Bethlehem\", \"Billings\", \"Birmingham\", \"Bloomington\", \"Boise\", \"Boise City\", \"Bonita Springs\", \"Boston\", \"Boulder\", \"Bradenton\", \"Bremerton\", \"Bridgeport\", \"Brighton\", \"Brownsville\", \"Bryan\", \"Buffalo\", \"Burbank\", \"Burlington\", \"Cambridge\", \"Canton\", \"Cape Coral\", \"Carrollton\", \"Cary\", \"Cathedral City\", \"Cedar Rapids\", \"Champaign\", \"Chandler\", \"Charleston\", \"Charlotte\", \"Chattanooga\", \"Chesapeake\", \"Chicago\", \"Chula Vista\", \"Cincinnati\", \"Clarke County\", \"Clarksville\", \"Clearwater\", \"Cleveland\", \"College Station\", \"Colorado Springs\", \"Columbia\", \"Columbus\", \"Concord\", \"Coral Springs\", \"Corona\", \"Corpus Christi\", \"Costa Mesa\", \"Dallas\", \"Daly City\", \"Danbury\", \"Davenport\", \"Davidson County\", \"Dayton\", \"Daytona Beach\", \"Deltona\", \"Denton\", \"Denver\", \"Des Moines\", \"Detroit\", \"Downey\", \"Duluth\", \"Durham\", \"El Monte\", \"El Paso\", \"Elizabeth\", \"Elk Grove\", \"Elkhart\", \"Erie\", \"Escondido\", \"Eugene\", \"Evansville\", \"Fairfield\", \"Fargo\", \"Fayetteville\", \"Fitchburg\", \"Flint\", \"Fontana\", \"Fort Collins\", \"Fort Lauderdale\", \"Fort Smith\", \"Fort Walton Beach\", \"Fort Wayne\", \"Fort Worth\", \"Frederick\", \"Fremont\", \"Fresno\", \"Fullerton\", \"Gainesville\", \"Garden Grove\", \"Garland\", \"Gastonia\", \"Gilbert\", \"Glendale\", \"Grand Prairie\", \"Grand Rapids\", \"Grayslake\", \"Green Bay\", \"GreenBay\", \"Greensboro\", \"Greenville\", \"Gulfport-Biloxi\", \"Hagerstown\", \"Hamilton\",\"Hampton\", \"Harlingen\", \"Harrisburg\", \"Hartford\", \"Havre de Grace\", \"Hayward\", \"Hemet\", \"Henderson\", \"Hesperia\", \"Hialeah\", \"Hickory\", \"High Point\", \"Hollywood\", \"Honolulu\", \"Houma\", \"Houston\", \"Howell\", \"Huntington\", \"Huntington Beach\", \"Huntsville\", \"Independence\", \"Indianapolis\", \"Inglewood\", \"Irvine\", \"Irving\", \"Jackson\", \"Jacksonville\", \"Jefferson\", \"Jersey City\", \"Johnson City\", \"Joliet\", \"Kailua\", \"Kalamazoo\", \"Kaneohe\", \"Kansas City\", \"Kennewick\", \"Kenosha\", \"Killeen\", \"Kissimmee\", \"Knoxville\", \"Lacey\", \"Lafayette\", \"Lake Charles\", \"Lakeland\", \"Lakewood\", \"Lancaster\", \"Lansing\", \"Laredo\", \"Las Cruces\", \"Las Vegas\", \"Layton\", \"Leominster\", \"Lewisville\", \"Lexington\", \"Lincoln\", \"Little Rock\", \"Long Beach\", \"Lorain\", \"Los Angeles\", \"Louisville\", \"Lowell\", \"Lubbock\", \"Macon\", \"Madison\", \"Manchester\", \"Marina\", \"Marysville\", \"McAllen\", \"McHenry\", \"Medford\", \"Melbourne\", \"Memphis\", \"Merced\", \"Mesa\", \"Mesquite\", \"Miami\", \"Milwaukee\", \"Minneapolis\", \"Miramar\", \"Mission Viejo\", \"Mobile\", \"Modesto\", \"Monroe\", \"Monterey\", \"Montgomery\", \"Moreno Valley\", \"Murfreesboro\", \"Murrieta\", \"Muskegon\", \"Myrtle Beach\", \"Naperville\", \"Naples\", \"Nashua\", \"Nashville\", \"New Bedford\", \"New Haven\", \"New London\", \"New Orleans\", \"New York\", \"New York City\", \"Newark\", \"Newburgh\", \"Newport News\", \"Norfolk\", \"Normal\", \"Norman\", \"North Charleston\", \"North Las Vegas\", \"North Port\", \"Norwalk\", \"Norwich\", \"Oakland\", \"Ocala\", \"Oceanside\", \"Odessa\", \"Ogden\", \"Oklahoma City\", \"Olathe\", \"Olympia\", \"Omaha\", \"Ontario\", \"Orange\", \"Orem\", \"Orlando\", \"Overland Park\", \"Oxnard\", \"Palm Bay\", \"Palm Springs\", \"Palmdale\", \"Panama City\", \"Pasadena\", \"Paterson\", \"Pembroke Pines\", \"Pensacola\", \"Peoria\", \"Philadelphia\", \"Phoenix\", \"Pittsburgh\", \"Plano\", \"Pomona\", \"Pompano Beach\", \"Port Arthur\", \"Port Orange\", \"Port Saint Lucie\", \"Port St. Lucie\", \"Portland\", \"Portsmouth\", \"Poughkeepsie\", \"Providence\", \"Provo\", \"Pueblo\", \"Punta Gorda\", \"Racine\", \"Raleigh\", \"Rancho Cucamonga\", \"Reading\", \"Redding\", \"Reno\", \"Richland\", \"Richmond\", \"Richmond County\", \"Riverside\", \"Roanoke\", \"Rochester\", \"Rockford\", \"Roseville\", \"Round Lake Beach\", \"Sacramento\", \"Saginaw\", \"Saint Louis\", \"Saint Paul\", \"Saint Petersburg\", \"Salem\", \"Salinas\", \"Salt Lake City\", \"San Antonio\", \"San Bernardino\", \"San Buenaventura\", \"San Diego\", \"San Francisco\", \"San Jose\", \"Santa Ana\", \"Santa Barbara\", \"Santa Clara\", \"Santa Clarita\", \"Santa Cruz\", \"Santa Maria\", \"Santa Rosa\", \"Sarasota\", \"Savannah\", \"Scottsdale\", \"Scranton\", \"Seaside\", \"Seattle\", \"Sebastian\", \"Shreveport\", \"Simi Valley\", \"Sioux City\", \"Sioux Falls\", \"South Bend\", \"South Lyon\", \"Spartanburg\", \"Spokane\", \"Springdale\", \"Springfield\", \"St. Louis\", \"St. Paul\", \"St. Petersburg\", \"Stamford\", \"Sterling Heights\", \"Stockton\", \"Sunnyvale\", \"Syracuse\", \"Tacoma\", \"Tallahassee\", \"Tampa\", \"Temecula\", \"Tempe\", \"Thornton\", \"Thousand Oaks\", \"Toledo\", \"Topeka\", \"Torrance\", \"Trenton\", \"Tucson\", \"Tulsa\", \"Tuscaloosa\", \"Tyler\", \"Utica\", \"Vallejo\", \"Vancouver\", \"Vero Beach\", \"Victorville\", \"Virginia Beach\", \"Visalia\", \"Waco\", \"Warren\", \"Washington\", \"Waterbury\", \"Waterloo\", \"West Covina\", \"West Valley City\", \"Westminster\", \"Wichita\", \"Wilmington\", \"Winston\", \"Winter Haven\", \"Worcester\", \"Yakima\", \"Yonkers\", \"York\", \"Youngstown\"]\n",
    "\n",
    "# list of all the US states\n",
    "states = {\n",
    "    'AK': 'Alaska',\n",
    "    'AL': 'Alabama',\n",
    "    'AR': 'Arkansas',\n",
    "    'AZ': 'Arizona',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DC': 'District of Columbia',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'IA': 'Iowa',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MD': 'Maryland',\n",
    "    'ME': 'Maine',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MO': 'Missouri',\n",
    "    'MS': 'Mississippi',\n",
    "    'MT': 'Montana',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'NE': 'Nebraska',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NV': 'Nevada',\n",
    "    'NY': 'New York',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VA': 'Virginia',\n",
    "    'VT': 'Vermont',\n",
    "    'WA': 'Washington',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WV': 'West Virginia',\n",
    "    'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "# the data frame which hold the information for all the required columns\n",
    "extracted_info_df = pd.DataFrame(columns=['First_Name','Last_Name','Address','Email','Phone_1','Phone_2','City','County','State','Company name'])\n",
    "words = ''\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "# check if csv file exists\n",
    "if(os.path.isfile(\"Assignment 0 Part A.csv\")):\n",
    "    dataframe = pd.read_csv(\"Assignment 0 Part A.csv\")\n",
    "else:\n",
    "    print(\"File not found -> Assignment 0 Part A.csv\")\n",
    "    exit\n",
    "\n",
    "# read by default 1st sheet of an excel file\n",
    "dataframe = pd.read_csv(\"Assignment 0 Part A.csv\")\n",
    "\n",
    "# method to extract first and last name\n",
    "def extract_name(sentence):\n",
    "    \"\"\"Extracts the first name and last name from the sentence\n",
    "       Logic used : extract the first two words of the input sentence excluding the symbols\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : str, mandatory\n",
    "            The input sentence from which the names need to be extracted\n",
    "\n",
    "        returns the first name and the last name\n",
    "        \"\"\"\n",
    "    global words\n",
    "    words = re.findall(r'\\b\\w+\\b', sentence)\n",
    "    return words[:2]\n",
    "\n",
    "# method to extract address\n",
    "def extract_address(sentence):\n",
    "    \"\"\"Extracts the address from the sentence\n",
    "       Logic used : checking if there is a phrase in the sentence which begins with numbers and ends with wither St or Blvd string\n",
    "       All the addresses in the given csv follow this format for the address\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : str, mandatory\n",
    "            The input sentence from which the address needs to be extracted\n",
    "\n",
    "        returns the extracted address if found, else returns None\n",
    "        \"\"\"\n",
    "    address_pattern = r'\\b\\d.*?(St|Blvd)\\b'\n",
    "    match = re.search(address_pattern, sentence)\n",
    "    if match:\n",
    "        return match\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# method to extract email\n",
    "def extract_email(sentence):\n",
    "    \"\"\"Extracts the email from the sentence\n",
    "       Logic used : regex applied appropriately to find format of email and extract it out from sentence\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : str, mandatory\n",
    "            The input sentence from which the email needs to be extracted\n",
    "\n",
    "        returns the extracted email if found, else returns None\n",
    "        \"\"\"\n",
    "    words = sentence.split()\n",
    "    email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]+.$'\n",
    "    #print(words)\n",
    "    matching_email = [word for word in words if re.search(email_pattern, word)]\n",
    "    return matching_email\n",
    "\n",
    "#method to extract county\n",
    "def extract_words_with_county(sentence):\n",
    "    \"\"\"Extracts the county name from the sentence\n",
    "       Logic used : checks if there is a word County in the sentence and extracts the word preceding the word county \n",
    "       which will always be the name of the county in the given csv\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : str, mandatory\n",
    "            The input sentence from which the county needs to be extracted\n",
    "\n",
    "        returns the extracted county name if found, else returns None\n",
    "        \"\"\"\n",
    "    pattern = r'\\b(\\w+)\\s+county\\b'\n",
    "    match = re.search(pattern, sentence, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_city(sentence):\n",
    "    \"\"\"Extracts the US state name from the sentence\n",
    "       Logic used : we have a taken the already available list of US cities(some cities in the list might be missing, but all the major ones are included). \n",
    "       We are removing the the commas from the sentence to make it easier for pattern matching in the subsequent steps.\n",
    "       We are checking if there exists a phrase in the sentence which begins with the first name and last name of the person followed by ':' and contains the prepositions 'in' or 'of' \n",
    "       and includes exactly one word after the preposition. If such a phrase exists, we are taking out only the last word of that phrase and checking if that word matches any element of the\n",
    "       US cities list. If there is a match then the city name is found.\n",
    "\n",
    "       Note : We have assumed that only the US cities are present in the given CSV\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       sentence : str, mandatory\n",
    "       The input sentence from which the city name needs to be extracted\n",
    "\n",
    "       returns the extracted city name if found, else returns None\n",
    "       \"\"\"\n",
    "    name = words[0] + \" \"+words[1]\n",
    "    fmt_sentence = re.sub(',', '', sentence)\n",
    "    pattern_string = f\"{re.escape(name)}: (.*?)(from|of|in)\\s+(\\w+)\"\n",
    "    pattern = re.compile(pattern_string)\n",
    "    match = pattern.search(fmt_sentence)\n",
    "    temp = match[0].split()\n",
    "    if match:\n",
    "        isCity = US_city_names.count(temp[-1])\n",
    "        if isCity > 0:\n",
    "            return temp[-1]\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "            return None\n",
    "    \n",
    "def extract_phone_numbers(sentence):\n",
    "    \"\"\" Extracts the phone number from the sentence\n",
    "        Logic used : regex applied appropriately to find format of USA phone number and extract it out from sentence\n",
    "        Note : We have assumed that only the US phone numbers are present in the given CSV\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : str, mandatory\n",
    "            The input sentence from which the phone numbers needs to be extracted\n",
    "\n",
    "        returns the extracted phone numbers if found, else returns None\n",
    "        \"\"\"\n",
    "    phone_num_pattern = r'\\b(?:\\+?1\\s*[-.\\s]?)?\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}\\b'\n",
    "    matches = re.findall(phone_num_pattern, sentence)\n",
    "    return matches\n",
    "\n",
    "def extract_state(sentence):\n",
    "    \"\"\" Extracts the US state name from the sentence\n",
    "        Logic used : we have a taken the already available list of US states. We are checking if any word of the sentence matches with any \n",
    "        elements of this states list.\n",
    "        Note : We have assumed that only the US states are present in the given CSV\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sentence : str, mandatory\n",
    "            The input sentence from which the states needs to be extracted\n",
    "\n",
    "        returns the extracted US state if found, else returns None\n",
    "        \"\"\"\n",
    "    state_codes = list(states.keys())\n",
    "    words = re.findall(r'\\b\\w+\\b', sentence)\n",
    "    result = (set(state_codes) & set(words))\n",
    "    if result:\n",
    "        return list(result)[0] +\"-\"+states[list(result)[0]]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_company_name(sentence):\n",
    "    \"\"\"Extracts the company name from the sentence\n",
    "       Logic used : We are removing the the commas from the sentence to make it easier for pattern matching in the subsequent steps.\n",
    "       We are checking if there exists a phrase in the sentence which begins with the first name and last name of the person and contains 'of' or 'at' or 'from'\n",
    "       and includes exactly one word after (of/at/from). If such a phrase exists, we are taking out only the last word of that phrase, checking that its not a city name, then \n",
    "       if its not a city name we are considering that to be the company name.This logic has worked all the rows and accuracy is more than 90%. But if the company name includes multiple words,\n",
    "       only the first word is considered the rest of it is ignored.\n",
    "       \n",
    "       Parameters\n",
    "       ----------\n",
    "       sentence : str, mandatory\n",
    "       The input sentence from which the company name needs to be extracted\n",
    "\n",
    "       returns the extracted company name if found, else returns None\n",
    "       \"\"\"\n",
    "    name = words[0] + \" \"+words[1]\n",
    "    fmt_sentence = re.sub(',', '', sentence)\n",
    "    pattern_string = f\"{re.escape(name)} (.*?)(at|of|from)\\s+(\\w+)\"\n",
    "    pattern = re.compile(pattern_string)\n",
    "    match = pattern.search(fmt_sentence)\n",
    "    if match:\n",
    "        temp = match[0].split()\n",
    "        isCity = US_city_names.count(temp[-1])\n",
    "        if isCity < 1:\n",
    "            return (temp[-1])\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def exec_engine():\n",
    "    \"\"\"This method drives the process of extracting the required information and populating the final dataframe to be displayed.\n",
    "       It calls all the other methods which extract necessary information.\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       no parameters\n",
    "\n",
    "       displays the final dataframe populated with all the information\n",
    "       \"\"\"\n",
    "    for i in range(0, 5):\n",
    "        names = extract_name(dataframe.Description[i])\n",
    "        email = extract_email(dataframe.Description[i])\n",
    "        county = extract_words_with_county(dataframe.Description[i])\n",
    "        phone_nums = extract_phone_numbers(dataframe.Description[i])\n",
    "        address = extract_address(dataframe.Description[i])\n",
    "        state = extract_state(dataframe.Description[i])\n",
    "        company = extract_company_name(dataframe.Description[i])\n",
    "        city = extract_city(dataframe.Description[i])\n",
    "\n",
    "        if len(names) > 1:\n",
    "            extracted_info_df.at[i, 'First_Name'] = names[0]\n",
    "            extracted_info_df.at[i, 'Last_Name'] = names[1]\n",
    "        if address is not None:\n",
    "            extracted_info_df.at[i, 'Address']= address[0]\n",
    "        if len(email) > 0:\n",
    "            fmt_email = email.pop().rstrip(string.punctuation) \n",
    "            extracted_info_df.at[i, 'Email']= fmt_email\n",
    "        if county is not None:\n",
    "            extracted_info_df.at[i, 'County'] = county[0]\n",
    "        if city is not None:\n",
    "            extracted_info_df.at[i, 'City'] = city\n",
    "        if state is not None:\n",
    "            extracted_info_df.at[i, 'State'] = state\n",
    "        if company is not None:\n",
    "            extracted_info_df.at[i, 'Company name'] = company\n",
    "        if len(phone_nums)>0:    \n",
    "            extracted_info_df.at[i, 'Phone_1'] = phone_nums[0]\n",
    "        if len(phone_nums)>1:\n",
    "            extracted_info_df.at[i, 'Phone_2'] = phone_nums[1]\n",
    "\n",
    "exec_engine()\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Do not wrap the DataFrame\n",
    "\n",
    "# Display the DataFrame\n",
    "\n",
    "display(extracted_info_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part B Solution\n",
    "\n",
    "##### Approach \n",
    "###### 1 . As we can see there are several conditions with the word disease or diseases in the them. Since the word diseases encompasses the word 'disease' we have decided to replace 'diseases' with 'disease' in every condition, to ensure that condition does not get missed out. (As we can see for the condition of 'Kidney Diseases' where the frequency of that word increased after we changed it to 'Kidney Disease' where both indicate the exact same thing.)\n",
    "###### 2. There are three conditions in the given list which encompass multiple diseases which are a) Influenza and Pneumonia b) Accidents/injuries c) HIV/AIDS. These conditions appear multiple times in the journal as parts, but not in exact same combination. So we have split the condition based on 'and' or '/', calculated the individual frequency for the disease and added them and updated that as the final frequency. For example : Influenza and Pneumonia -> Influenza occurs 12 times and Pneumonia - 16 times, then the frequency for the condition Influenza and Pneumonia becomes 28 times. Note : When checking the occurences we are ignoring the casing of the strings. Special note for condition c) HIV/AIDS. We manually checked and observed that the condition HIV/AIDS never appears in any of the given volumes, and incorporating logic to check this condition required including case sensitivity, we took a call to add logic to ignore that condition, since it does not appear even once in any of the volumes.\n",
    "###### 3. Condition Dengue fever : We can observe that the condition 'Dengue fever' never appears in any of the volumes, but condition 'Dengue' does appear with significant frequency. Since both are the same condition, we have replaced Dengue fever with Dengue to get the accurate count.\n",
    "###### Note: The main conditions and the headers that we are considering are exactly same as given in the problem statement. We have added code and parsing the condition only during camparison and frequency calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Heart disease</th>\n",
       "      <th>Cancer</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Respiratory diseases</th>\n",
       "      <th>Alzheimer's disease</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Influenza and Pneumonia</th>\n",
       "      <th>Kidney diseases</th>\n",
       "      <th>Septicemia</th>\n",
       "      <th>Liver disease</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Parkinson's disease</th>\n",
       "      <th>Chronic lower respiratory disease</th>\n",
       "      <th>Accidents/injuries</th>\n",
       "      <th>Osteoporosis</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Oral health issues</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>Tuberculosis</th>\n",
       "      <th>Malaria</th>\n",
       "      <th>Dengue fever</th>\n",
       "      <th>Hepatitis</th>\n",
       "      <th>Epilepsy</th>\n",
       "      <th>Multiple sclerosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Volume 1</th>\n",
       "      <td>4</td>\n",
       "      <td>97</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>374</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>269</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume 2</th>\n",
       "      <td>23</td>\n",
       "      <td>1335</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>142</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume 3</th>\n",
       "      <td>67</td>\n",
       "      <td>224</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1066</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>383</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume 4</th>\n",
       "      <td>15</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume 5</th>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>530</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Heart disease  Cancer  Stroke  Respiratory diseases  Alzheimer's disease  Diabetes  Influenza and Pneumonia  Kidney diseases  Septicemia  Liver disease  Hypertension  Parkinson's disease  Chronic lower respiratory disease  Accidents/injuries  Osteoporosis  Asthma  Depression  Oral health issues  HIV/AIDS  Tuberculosis  Malaria  Dengue fever  Hepatitis  Epilepsy  Multiple sclerosis\n",
       "Volume 1              4      97       9                     1                    0         9                      374                2           0              0             0                    0                                  0                  36             0       6          41                   0         0           125      269            78          0         9                   0\n",
       "Volume 2             23    1335      10                     0                    0       227                      105                3           0              4             0                    0                                  0                  55             1      10          93                   0         0           130      142             3         71        12                   0\n",
       "Volume 3             67     224      12                     0                    0         5                     1066                6           0              0             0                    0                                  0                  79             0     383          73                   0         0           192       83             0          2         4                   0\n",
       "Volume 4             15     116       3                     0                    0        47                       25               14           0              2             0                    0                                  0                  56             0       1          27                   0         0            37       70             0          2        35                   0\n",
       "Volume 5             10      41      97                     0                    0        33                       58                0           0              0             0                    1                                  0                 172             1      15         124                   0         0            36       57             1         17       530                   8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# assume txt and this file under same path\n",
    "\n",
    "# use to output the form\n",
    "health_conditions = [\n",
    "    \"Heart disease\", \"Cancer\", \"Stroke\", \"Respiratory diseases\", \"Alzheimer's disease\",\n",
    "    \"Diabetes\", \"Influenza and Pneumonia\", \"Kidney diseases\", \"Septicemia\", \"Liver disease\",\n",
    "    \"Hypertension\", \"Parkinson's disease\", \"Chronic lower respiratory disease\", \"Accidents/injuries\",\n",
    "    \"Osteoporosis\", \"Asthma\", \"Depression\", \"Oral health issues\", \"HIV/AIDS\", \"Tuberculosis\",\n",
    "    \"Malaria\", \"Dengue fever\", \"Hepatitis\", \"Epilepsy\", \"Multiple sclerosis\"\n",
    "]\n",
    "\n",
    "\n",
    "def helper_func(diseases,text):\n",
    "    disease_len = 0\n",
    "    disease = diseases[0].strip()\n",
    "    pattern = re.compile(re.escape(disease), re.IGNORECASE)\n",
    "    disease_len = disease_len + len(pattern.findall(text))\n",
    "    disease = diseases[1].strip()\n",
    "    pattern = re.compile(re.escape(disease), re.IGNORECASE)\n",
    "    disease_len = disease_len + len(pattern.findall(text))\n",
    "    return disease_len\n",
    "\n",
    "# A regular expression pattern which is for any special characters, and setting the case to be ignored, and return the number of times the condition is found in the text.\n",
    "def count_occurrences(text, condition):\n",
    "    \n",
    "    diseases = []\n",
    "    fmt_condition = condition.replace(\"diseases\", \"disease\")\n",
    "\n",
    "    if ('/' in fmt_condition and len(fmt_condition) > 9):\n",
    "        diseases = fmt_condition.split('/')\n",
    "        return helper_func(diseases, text)\n",
    "\n",
    "    elif ('and' in fmt_condition):\n",
    "        diseases = fmt_condition.split('and')\n",
    "        return helper_func(diseases, text)\n",
    "    \n",
    "    elif ('Dengue' in fmt_condition):\n",
    "        fmt_condition = \"Dengue\"\n",
    "        pattern = re.compile(re.escape(fmt_condition), re.IGNORECASE)\n",
    "    else:\n",
    "        pattern = re.compile(re.escape(fmt_condition), re.IGNORECASE)\n",
    "\n",
    "    return len(pattern.findall(text))\n",
    "\n",
    "# try to read UTF-8 encoding at first, if have error, try ISO-8859-1 then. And this function use count_occurrences to count the health conditions.\n",
    "for volume_number in range(1, 6):\n",
    "    file_path = f'A system of practical medicine_v{volume_number}.txt'\n",
    "    try:\n",
    "        # UTF-8 encoding\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            volume_text = file.read()\n",
    "    except UnicodeDecodeError:\n",
    "        # ISO-8859-1 if UTF-8 contain error\n",
    "        with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "            volume_text = file.read()\n",
    "    volume_counts = {condition: count_occurrences(volume_text, condition) for condition in health_conditions}\n",
    "    df_volume = pd.DataFrame([volume_counts], index=[f\"Volume {volume_number}\"])\n",
    "    df_volume.to_csv(f'volume_{volume_number}_counts.csv')\n",
    "\n",
    "# output\n",
    "# create an empty DataFrame: all_volumes_df\n",
    "all_volumes_df = pd.DataFrame()\n",
    "\n",
    "for volume_number in range(1, 6):\n",
    "    file_name = f'volume_{volume_number}_counts.csv'\n",
    "    df = pd.read_csv(file_name, index_col=0)\n",
    "    all_volumes_df = pd.concat([all_volumes_df, df])\n",
    "\n",
    "# display\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Do not wrap the DataFrame\n",
    "display(all_volumes_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
